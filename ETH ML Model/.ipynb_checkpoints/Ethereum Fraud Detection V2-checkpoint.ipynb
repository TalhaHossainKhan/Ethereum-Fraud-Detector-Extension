{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b30843",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pycm import ConfusionMatrix, Compare\n",
    "\n",
    "\n",
    "FOLD_NUMBER = 10\n",
    "RANDOM_STATE = 23\n",
    "METRIC_LIST = [\"Accuracy\", \"F1\", \"Kappa\", \"Precision\", \"Recall\"]\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "df = pd.read_csv(\"3.csv\")\n",
    "\n",
    "# corr = df.iloc[:,2:].corr()\n",
    "# mask = np.zeros_like(corr)\n",
    "# mask[np.triu_indices_from(mask)]=True\n",
    "# with sns.axes_style('white'):\n",
    "#     fig, ax = plt.subplots(figsize=(18,10))\n",
    "#     sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, square=True)\n",
    "    \n",
    "positive_sample = df[df[\"Flag\"] == 1]\n",
    "negative_sample = df[df[\"Flag\"] == 0].sample(len(positive_sample), random_state = RANDOM_STATE)\n",
    "data = pd.concat([negative_sample, positive_sample], axis = 0)\n",
    "y = data[\"Flag\"]\n",
    "X = data.iloc[:,2:]\n",
    "\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].fillna(X[col].mean())\n",
    "    \n",
    "rf_params = {\"n_estimators\": 150, \"criterion\": \"entropy\", \"bootstrap\": True}\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X, y)\n",
    "kf = KFold(n_splits=10, random_state = RANDOM_STATE, shuffle=True)\n",
    "cm_metric_list = []\n",
    "rf_cm_worst = None\n",
    "rf_cm_best = None\n",
    "rf_cm_list = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "#     cm = ConfusionMatrix(actual_vector = y_test.values, predict_vector = rf_model.predict(X_test))\n",
    "#     cm_metric_list.append({\"Accuracy\":cm.Overall_ACC, \"F1\": cm.F1[1], \"Kappa\": cm.Kappa, \"Precision\":cm.PPV[1]\n",
    "#                         , \"Recall\": cm.TPR[1]})\n",
    "#     cm.relabel({1: \"Fraud\", 0:\"Non-Fraud\"})\n",
    "#     rf_cm_list.append(cm)\n",
    "#     if rf_cm_worst is None:\n",
    "#         rf_cm_worst = cm\n",
    "#     else:\n",
    "#         if cm.Overall_ACC < rf_cm_worst.Overall_ACC:\n",
    "#             rf_cm_worst = cm\n",
    "\n",
    "#     if rf_cm_best is None:\n",
    "#         rf_cm_best = cm\n",
    "#     else:\n",
    "#         if cm.Overall_ACC > rf_cm_best.Overall_ACC:\n",
    "#             rf_cm_best = cm\n",
    "            \n",
    "\n",
    "# print(\"Model Name: Random Forest Classifier\\n\")\n",
    "# print(\"10-Fold Metrics: \\n\")\n",
    "# for metric in METRIC_LIST:\n",
    "#     temp = []\n",
    "#     for item in cm_metric_list:\n",
    "#         temp.append(item[metric])\n",
    "#     print(\"{0} : {1}\\n\".format(metric, np.mean(temp).round(2)))\n",
    "# rf_cm_worst.plot(title=\"Random Forest Worst\", number_label=True)\n",
    "# rf_cm_best.plot(title=\"Random Forest Best\", number_label=True)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "769d8f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8891629955947137\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 141\u001b[0m\n\u001b[0;32m    138\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(rf_model, X_scaled, y, cv\u001b[38;5;241m=\u001b[39mkf, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(scores))\n\u001b[1;32m--> 141\u001b[0m Predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict([PredictArray])\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(Predict)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "address = \"0x690B9A9E9aa1C9dB991C7721a92d351Db4FaC990\"\n",
    "address = address.lower()\n",
    "\n",
    "api_key = \"WY5W2MXQZBTUJZET6TQSNS5XXMU1NBBKH1\"\n",
    "\n",
    "url = \"https://api.etherscan.io/api\"\n",
    "\n",
    "params = {\n",
    "    \"module\": \"account\",\n",
    "    \"action\": \"txlist\",\n",
    "    \"address\": address,\n",
    "    \"startblock\": 0,\n",
    "    \"endblock\": 99999999,\n",
    "    \"sort\": \"asc\",\n",
    "    \"page\": 1,\n",
    "    \"offset\": 10000,\n",
    "    \"apikey\": api_key\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Extracting the relevant information\n",
    "transactions = data[\"result\"]\n",
    "\n",
    "# Define empty lists to store the extracted data\n",
    "timestamps = []\n",
    "from_addresses = []\n",
    "to_addresses = []\n",
    "values = []\n",
    "\n",
    "# Iterate over the transactions and extract the desired fields\n",
    "for transaction in transactions:\n",
    "    timestamp_unix = int(transaction[\"timeStamp\"])\n",
    "    \n",
    "    # Convert timestamp from Unix time to datetime object\n",
    "    timestamp = datetime.utcfromtimestamp(timestamp_unix)\n",
    "    \n",
    "    from_address = transaction[\"from\"]\n",
    "    to_address = transaction[\"to\"]\n",
    "    value_wei = int(transaction[\"value\"])\n",
    "\n",
    "    # Convert value from wei to ether\n",
    "    value_ether = value_wei / 10**18\n",
    "\n",
    "    # Append the extracted data to the respective lists\n",
    "    timestamps.append(timestamp)\n",
    "    from_addresses.append(from_address)\n",
    "    to_addresses.append(to_address)\n",
    "    values.append(value_ether)\n",
    "\n",
    "# Calculate the time difference between adjacent timestamps in minutes\n",
    "time_diff_minutes = []\n",
    "sent_minute = []\n",
    "received_minute = []\n",
    "sent_val = []\n",
    "received_val = []\n",
    "for i in range(1, len(timestamps)):\n",
    "    curr_time = timestamps[i]\n",
    "    prev_time = timestamps[i - 1]\n",
    "    diff = (curr_time - prev_time).total_seconds() / 60\n",
    "    time_diff_minutes.append(diff)\n",
    "    \n",
    "    if from_addresses[i - 1] == address:\n",
    "        sent_minute.append(diff)\n",
    "        sent_val.append(values[i-1])\n",
    "        \n",
    "    if to_addresses[i - 1] == address: \n",
    "        received_minute.append(diff)\n",
    "        received_val.append(values[i-1])\n",
    "\n",
    "# Calculate the average of values in sent_minute and received_minute arrays\n",
    "Avg_min_between_sent_tnx = sum(sent_minute) / len(sent_minute) if sent_minute else 0\n",
    "Avg_min_between_received_tnx = sum(received_minute) / len(received_minute) if received_minute else 0\n",
    "\n",
    "# Store the number of unique elements in from_addresses and to_addresses arrays\n",
    "Average_of_Unique_Sent_To_Addresses = len(set(from_addresses))\n",
    "Average_of_Unique_Received_From_Addresses = len(set(to_addresses))\n",
    "\n",
    "# Store the number of elements in sent_minute and received_minute arrays\n",
    "Sent_tnx = len(sent_minute)\n",
    "Received_tnx = len(received_minute)\n",
    "\n",
    "# Find the minimum, maximum, and average value from sent_val array\n",
    "min_val_sent = min(sent_val) if sent_val else 0\n",
    "max_val_sent = max(sent_val) if sent_val else 0\n",
    "avg_val_sent = sum(sent_val) / len(sent_val) if sent_val else 0\n",
    "total_Ether_sent = sum(sent_val)\n",
    "\n",
    "# Find the minimum, maximum, and average value from received_val array\n",
    "min_value_received = min(received_val) if received_val else 0\n",
    "max_value_received = max(received_val) if received_val else 0\n",
    "avg_value_received = sum(received_val) / len(received_val) if received_val else 0\n",
    "total_ether_received = sum(received_val)\n",
    "\n",
    "#Totalling\n",
    "total_transactions_including_tnx_to_create_contract = Sent_tnx + Received_tnx\n",
    "total_ether_balance = total_ether_received - total_Ether_sent  \n",
    "\n",
    "\n",
    "PredictArray = [Avg_min_between_received_tnx, Avg_min_between_sent_tnx, Sent_tnx, Received_tnx, Average_of_Unique_Received_From_Addresses,\n",
    "               Average_of_Unique_Sent_To_Addresses, min_value_received, max_value_received, avg_value_received, min_val_sent,\n",
    "               max_val_sent, avg_val_sent, total_transactions_including_tnx_to_create_contract, total_Ether_sent, total_ether_received,\n",
    "               total_ether_balance]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "df = pd.read_csv(\"3.csv\")\n",
    "\n",
    "positive_sample = df[df[\"Flag\"] == 1]\n",
    "negative_sample = df[df[\"Flag\"] == 0].sample(len(positive_sample), random_state=23)\n",
    "data = pd.concat([negative_sample, positive_sample], axis=0)\n",
    "y = data[\"Flag\"]\n",
    "X = data.iloc[:, 2:]\n",
    "\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].fillna(X[col].mean())\n",
    "\n",
    "rf_params = {\"n_estimators\": 150, \"criterion\": \"entropy\", \"bootstrap\": True}\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=23, shuffle=True)\n",
    "scores = cross_val_score(rf_model, X_scaled, y, cv=kf, n_jobs=-1)\n",
    "\n",
    "print(\"Average accuracy:\", np.mean(scores))\n",
    "Predict = rf_model.predict([PredictArray])\n",
    "print(Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3414e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
